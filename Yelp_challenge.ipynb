{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Dataset Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The average # of reviews and the average # of stars grouped by city and business category.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We first import the dataframe and select the relevant columns using the select function.\n",
    "Since each row has a group of categories we need to explode the categories first so that each row gets a single category, by which we later group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+------------------+------------------+\n",
      "|            city|        categories|        avg(stars)| avg(review_count)|\n",
      "+----------------+------------------+------------------+------------------+\n",
      "|Richmond Heights|          Shopping|               3.5|              10.5|\n",
      "|         Madison|  Laundry Services| 2.962962962962963| 6.851851851851852|\n",
      "|          Elyria|           Doctors|               2.5|               3.0|\n",
      "|            Mesa|Auto Customization|              4.25|12.857142857142858|\n",
      "|         Phoenix|              Pets| 4.073369565217392| 21.04076086956522|\n",
      "|         Toronto|Financial Services|           2.96875|          6.296875|\n",
      "|           Tempe|   Hotels & Travel| 3.258771929824561| 29.19298245614035|\n",
      "|        Surprise|          Shopping|3.5719424460431655|12.532374100719425|\n",
      "|       Henderson|             Pizza|3.3532608695652173|  96.3804347826087|\n",
      "|       Etobicoke|    Sporting Goods|             3.625| 6.583333333333333|\n",
      "+----------------+------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark as spark\n",
    "sc = spark.SparkContext()\n",
    "sql = spark.SQLContext(sc)\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "\n",
    "\n",
    "businessdf = sql.read.json('/Users/rohitsuvarna/Downloads/dataset/business.json')\n",
    "businessdf = sql.read.json('/Users/rohitsuvarna/Downloads/dataset/business.json')\n",
    "businessdf = businessdf.select('name','business_id','city','state','categories','stars','review_count')\n",
    "businessdf = businessdf.withColumn(\"categories\",func.explode(businessdf.categories))\n",
    "result1 = businessdf.groupBy('city',\"categories\").agg(func.avg(\"stars\") , func.avg(\"review_count\"))\n",
    "result1.show(10)\n",
    "result1.repartition(1).write.csv(\"Q1.csv\")\n",
    "#this will write df to single csv instead of writing diff csv acc to partitions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pivoting the business categories as columns, I show the average # stars for each category, by (city,state):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we use the pivot function to transform the categories from row to columns.Then in the next step we group by\n",
    "city,state. Since since too many columns to show, i have shown the resulting dataframe using few selected categries like 'food', 'chinese' and 'restaurants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+------------------+------------------+\n",
      "|                city|state|              Food|           Chinese|       Restaurants|\n",
      "+--------------------+-----+------------------+------------------+------------------+\n",
      "|                Mesa|   AZ| 3.551829268292683|3.2349397590361444|3.3077994428969357|\n",
      "|St-Benoît de Mirabel|   QC|               4.0|              null|               4.0|\n",
      "|      Cote-Saint-Luc|   QC|               5.0|              null|              3.75|\n",
      "|  Mont-Saint-Hilaire|   QC|               3.0|              null|3.5714285714285716|\n",
      "|         Monreoville|   PA|              null|              null|              null|\n",
      "|            Citibank|   NV|              null|              null|              null|\n",
      "|          Canonsburd|   PA|              null|              null|               1.0|\n",
      "|    Centennial Hills|   NV|              null|              null|              null|\n",
      "|         Scarborough|   ON|3.4651898734177213|3.2838983050847457|3.2822222222222224|\n",
      "|            Leonberg|   BY|              null|              null|              null|\n",
      "+--------------------+-----+------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using businessdf from previous part\n",
    "result2 = businessdf.groupBy('city','state').pivot('categories').avg('stars')\n",
    "result2_sel_cols = result2.select('city','state','Food','Chinese','Restaurants')\n",
    "result2_sel_cols.show(10)\n",
    "result2.repartition(1).write.csv(\"Q2.csv\")#this will write df to single csv instead of writing diff csv acc to partitions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The average rank (# stars) for businesses that are ‘Mexican’ category, AND offer takeout: (e.g. \"attributes\": {\"RestaurantsTakeOut\": true,…})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the business json and select the categories column and extract the ''attributes.RestaurantsTakeOut' as a column as well. Finally we filter the datafram so that it only has Mexican restaurants that offer takeout. Finally we find the average rank of these restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "businessdf = sql.read.json('/Users/rohitsuvarna/Downloads/dataset/business.json')\n",
    "businessdf = businessdf.withColumn(\"categories\",func.explode(businessdf.categories))\n",
    "businessdf = businessdf.select(\"name\",\"business_id\",'city','state','categories',\\\n",
    "                               'attributes.RestaurantsTakeOut','stars','review_count')\n",
    "businessdf = businessdf.filter((businessdf.categories == 'Mexican') & (businessdf.RestaurantsTakeOut == True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+-----+----------+------------------+-----+------------+\n",
      "|                name|         business_id|       city|state|categories|RestaurantsTakeOut|stars|review_count|\n",
      "+--------------------+--------------------+-----------+-----+----------+------------------+-----+------------+\n",
      "|             Rocky's|HmI9nhgOkrXlUr6KZ...| Pittsburgh|   PA|   Mexican|              true|  3.0|          15|\n",
      "|       El Pollo Loco|LDMCrFlGIFUN6L-FE...|  Las Vegas|   NV|   Mexican|              true|  3.0|          12|\n",
      "|Don Ruben's Mexic...|wsyNO9Ac4gqGYTBfN...|   Glendale|   AZ|   Mexican|              true|  4.5|         186|\n",
      "|Mariscos Playa Es...|YTqtM2WFhcMZGeAGA...|  Las Vegas|   NV|   Mexican|              true|  4.5|         330|\n",
      "|       Baja Miguel's|Oto60yDwk1z72WmfW...|  Las Vegas|   NV|   Mexican|              true|  3.0|         175|\n",
      "|         Gecko Grill|aP2Ma-Wx2lydppntC...|    Gilbert|   AZ|   Mexican|              true|  3.5|         201|\n",
      "|           Taco Bell|EUgHFeAvock2Ut3iW...|Monroeville|   PA|   Mexican|              true|  3.0|           6|\n",
      "|            Cafe Rio|Wbi-x-1Nbn6LFCMOS...|  Las Vegas|   NV|   Mexican|              true|  2.5|         189|\n",
      "| El Pollo Correteado|TqAXKLF1P5XAIG9Uq...|    Phoenix|   AZ|   Mexican|              true|  4.5|          13|\n",
      "|Chipotle Mexican ...|dXoeLzpG72P7F2Lwa...|   Surprise|   AZ|   Mexican|              true|  2.5|         102|\n",
      "+--------------------+--------------------+-----------+-----+----------+------------------+-----+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "businessdf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(stars)|\n",
      "+-----------------+\n",
      "|3.436754507628294|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_rank = businessdf.agg(func.avg('stars'))\n",
    "average_rank.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  For businesses within 15km of Toronto center, I show the average # stars and average # reviews by type of business category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Center: Toronto, CA\n",
    "Latitude: 43.6532° N, 79.3832° W\n",
    "The bounding circle for this problem is a ~15 km radius. A business falls in the region if it’s coordinates are within the circle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to import certain sql functions.For this question we also need to select the latitude and longitude, so that we can calculate the distance from Toronto using the co-rdinates by defining a distance UDF(user-defined function).  Then we filter using the distance functions to find only those businesses within 15 km of Toronto. Then we explode categories again since we need to group by categories. After this we groupby by category and find the average \n",
    "stars and review_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql.functions import udf,col,asc,desc\n",
    "from pyspark.sql.types import DoubleType,StringType,BooleanType\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+------------------+\n",
      "|      categories|        avg(stars)| avg(review_count)|\n",
      "+----------------+------------------+------------------+\n",
      "|  Dermatologists|3.2142857142857144| 9.285714285714286|\n",
      "|Historical Tours|              4.25|               8.0|\n",
      "|         Beaches| 4.208333333333333|             22.75|\n",
      "|   Skating Rinks|3.9444444444444446|              10.0|\n",
      "|   Data Recovery| 4.583333333333333|              14.5|\n",
      "|          Fondue|               3.5|              35.0|\n",
      "|     Boat Repair|               5.0|               6.0|\n",
      "|   Videographers| 4.333333333333333|               4.0|\n",
      "|    Contract Law|               4.0|              13.0|\n",
      "|        Day Spas|3.5242537313432836|14.951492537313433|\n",
      "+----------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "businessdf = sql.read.json('/Users/rohitsuvarna/Downloads/dataset/business.json')\n",
    "businessdf = businessdf.select('name','business_id','city','state','categories',\\\n",
    "                               'latitude','longitude','stars','review_count')\n",
    "businessdf = businessdf.dropna(subset=['latitude','longitude'])\n",
    "\n",
    "\n",
    "def dist(lat2,lon2):\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "    lat1 = math.radians(43.6532)\n",
    "    lon1 = math.radians(-79.3832)\n",
    "    R = 6371\n",
    "    return R*math.acos(math.sin(lat1)*math.sin(lat2) + math.cos(lat1)*math.cos(lat2)*math.cos(lon1 - lon2))\n",
    "    \n",
    "\n",
    "dist_udf = udf(dist,DoubleType())\n",
    "businessdf = businessdf.filter(dist_udf(businessdf.latitude,businessdf.longitude) <=15)\n",
    "businessdf = businessdf.withColumn(\"categories\",func.explode(businessdf.categories))\n",
    "businessdf = businessdf.groupBy(\"categories\").agg(func.avg(\"stars\"), func.avg(\"review_count\"))\n",
    "businessdf.show(10)\n",
    "businessdf.repartition(1).write.csv(\"Q4.csv\")#this will write df to single csv instead of writing diff csv acc to partitions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the top 10 and bottom 10 food businesses near Toronto (ranked by stars), I summarize star rating for reviews in January through May."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to recreate the Dataframe which has businesses near Toronto.Also we need to import the review json, which has information about when the reviews were posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "businessdf = sql.read.json('/Users/rohitsuvarna/Downloads/dataset/business.json')\n",
    "reviewdf = sql.read.json('/Users/rohitsuvarna/Downloads/dataset/review.json')\n",
    "businessdf = businessdf.select('name','business_id','city','state','categories','latitude','longitude','stars','review_count')\n",
    "businessdf = businessdf.dropna(subset=['latitude','longitude'])\n",
    "businessdf = businessdf.filter(dist_udf(businessdf.latitude,businessdf.longitude) <=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we explode the categories to select only the 'Food' businesses near Toronto as mentioned in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+-----+----------+-------------+--------------+-----+------------+\n",
      "|                name|         business_id|      city|state|categories|     latitude|     longitude|stars|review_count|\n",
      "+--------------------+--------------------+----------+-----+----------+-------------+--------------+-----+------------+\n",
      "|    The Tea Emporium|v2WhjAB3PIBA8J8Vx...|   Toronto|   ON|      Food|   43.6771258|   -79.3532848|  4.5|           7|\n",
      "|Paris Bakery & Pa...|kEq7eudoX5qdcaSLA...|   Toronto|   ON|      Food|   43.6624007|    -79.444706|  3.0|          16|\n",
      "|Fortinos Supermarket|UZShf6G75npKCCjiH...|North York|   ON|      Food|   43.7166569|   -79.4472576|  3.5|           9|\n",
      "|     Boardwalk Place|Z1r6b30Tg0n0ME4-Z...|   Toronto|   ON|      Food|   43.6630096|   -79.3108978|  3.0|          13|\n",
      "|      Sangria Lounge|v86J4q6ATA2ANm1fc...|   Toronto|   ON|      Food|43.6435365586|-79.4479535911|  3.5|          23|\n",
      "|          Second Cup|zcWit_aSGR5wiunYB...|   Toronto|   ON|      Food|   43.7036411|   -79.4136884|  4.0|           7|\n",
      "|  Toronto Distillery|o-0Nen1h78jiWZF_A...|   Toronto|   ON|      Food|   43.6707166|   -79.4646226|  3.5|           3|\n",
      "|  Brick Street Bread|x7lk5rE5u2KMV9pUm...|   Toronto|   ON|      Food|   43.6695943|   -79.3014347|  3.5|           6|\n",
      "|Just Desserts Res...|N-FKBizx_wu3L8mvD...|   Toronto|   ON|      Food|   43.6651601|   -79.3847901|  2.5|          39|\n",
      "|The Sweet Escape ...|f8dJLMQ7UxV1mri5t...|   Toronto|   ON|      Food|43.6506671963|-79.3586906249|  3.5|          34|\n",
      "+--------------------+--------------------+----------+-----+----------+-------------+--------------+-----+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "businessdf = businessdf.withColumn(\"categories\",func.explode(businessdf.categories))\n",
    "businessdf = businessdf.filter(businessdf.categories == 'Food')\n",
    "businessdf.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I join the business and review df on date, and then use another UDF to filter the dates between Jan and March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+---------+-----+-----+----------+\n",
      "|         name|         business_id|     city|state|stars|      date|\n",
      "+-------------+--------------------+---------+-----+-----+----------+\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    1|2016-07-14|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    5|2012-08-11|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    1|2014-05-14|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    5|2017-04-24|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    2|2015-02-11|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    4|2017-06-29|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    5|2016-05-26|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    3|2015-02-26|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    4|2016-09-08|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    4|2014-02-14|\n",
      "+-------------+--------------------+---------+-----+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Join_df = businessdf.join(reviewdf, businessdf.business_id == reviewdf.business_id).select(businessdf.name,businessdf.business_id,businessdf.city,businessdf.state,reviewdf.stars,reviewdf.date)\n",
    "Join_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+---------+-----+-----+----------+\n",
      "|         name|         business_id|     city|state|stars|      date|\n",
      "+-------------+--------------------+---------+-----+-----+----------+\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    1|2014-05-14|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    5|2017-04-24|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    2|2015-02-11|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    5|2016-05-26|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    3|2015-02-26|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    4|2014-02-14|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    5|2011-04-12|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    5|2015-05-23|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    4|2013-05-09|\n",
      "|Select Bakery|09OYbFNrS1n8u5gE6...|East York|   ON|    5|2013-02-06|\n",
      "+-------------+--------------------+---------+-----+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def Jan_thru_march(input_stri):\n",
    "    accept_months = ['01','02','03','04','05']\n",
    "    return input_stri[5:7] in accept_months\n",
    "\n",
    "Date_udf = udf(Jan_thru_march,StringType())\n",
    "Join_df = Join_df.filter(Date_udf(Join_df.date) == True)\n",
    "Join_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I find the average star ratings for all the businesses considering ratings only between Jan and March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              name|        avg(stars)|\n",
      "+------------------+------------------+\n",
      "|The Fresh Tea Shop|3.7058823529411766|\n",
      "|   Golden Bakeshop|               5.0|\n",
      "| Fahrenheit Coffee| 4.587155963302752|\n",
      "|     Sugar & Spice|3.3333333333333335|\n",
      "|     Umi's Kitchen|               4.5|\n",
      "|  House of Moments| 3.272727272727273|\n",
      "|           Penny's|               4.0|\n",
      "|      Oxford Fruit|               4.0|\n",
      "|             Corks|              4.25|\n",
      "|    The Cannonball|3.3529411764705883|\n",
      "+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Avg_df = Join_df.groupBy('name').avg('stars')\n",
    "Avg_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this I use 'order by' to find the top 10 businesses and then the bottom 10 businesses and finally I use Union to combine both the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                name|avg(stars)|\n",
      "+--------------------+----------+\n",
      "|2nd Nature Bakery...|       5.0|\n",
      "|        Academy Cafe|       5.0|\n",
      "|Alimentari Italia...|       5.0|\n",
      "|Allen's Scottish ...|       5.0|\n",
      "|          Amico Chef|       5.0|\n",
      "|Ararat Specialty ...|       5.0|\n",
      "|     Aren't We Sweet|       5.0|\n",
      "|      Avenue Seafood|       5.0|\n",
      "|        Azienda Cafe|       5.0|\n",
      "|   Babycake Cupcakes|       5.0|\n",
      "|  Alfredos Fine Food|       1.0|\n",
      "|    Amato King Pizza|       1.0|\n",
      "|         Baroli Cafe|       1.0|\n",
      "|          Blue Goose|       1.0|\n",
      "|        Bonga Buldak|       1.0|\n",
      "|        Castle Fruit|       1.0|\n",
      "|     Chocolate Charm|       1.0|\n",
      "|         Coffeeholic|       1.0|\n",
      "| Country Style Donut|       1.0|\n",
      "|               Doria|       1.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Best_df = Avg_df.orderBy(desc('avg(stars)'),asc('name'))\n",
    "Best_df = Best_df.limit(10)\n",
    "Worst_df = Avg_df.orderBy('avg(stars)',asc('name'))\n",
    "Worst_df = Worst_df.limit(10)\n",
    "Combined_df = Best_df.union(Worst_df)\n",
    "Combined_df.show()\n",
    "Combined_df.repartition(1).write.csv(\"Q5.csv\")#this will write df to single csv instead of writing diff csv acc to partitions "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
